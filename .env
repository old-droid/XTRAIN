# CPUWARP-ML Environment Configuration
# =====================================

# Dataset Configuration
# ---------------------
DATASET_ROOT=./datasets
IMAGENET_PATH=${DATASET_ROOT}/imagenet
CIFAR10_PATH=${DATASET_ROOT}/cifar-10-batches-py
CIFAR100_PATH=${DATASET_ROOT}/cifar-100-python
MNIST_PATH=${DATASET_ROOT}/mnist
COCO_PATH=${DATASET_ROOT}/coco
OPENIMAGES_PATH=${DATASET_ROOT}/openimages

# Text Datasets
WIKITEXT_PATH=${DATASET_ROOT}/wikitext
BOOKCORPUS_PATH=${DATASET_ROOT}/bookcorpus
COMMON_CRAWL_PATH=${DATASET_ROOT}/common_crawl
OSCAR_PATH=${DATASET_ROOT}/oscar

# Audio Datasets
LIBRISPEECH_PATH=${DATASET_ROOT}/librispeech
COMMON_VOICE_PATH=${DATASET_ROOT}/common_voice
VOXCELEB_PATH=${DATASET_ROOT}/voxceleb
AUDIOSET_PATH=${DATASET_ROOT}/audioset

# Multimodal Datasets
VQA_PATH=${DATASET_ROOT}/vqa
FLICKR30K_PATH=${DATASET_ROOT}/flickr30k
MSCOCO_CAPTIONS_PATH=${DATASET_ROOT}/mscoco_captions
CONCEPTUAL_CAPTIONS_PATH=${DATASET_ROOT}/conceptual_captions

# Model Configuration
# ------------------
# CNN Models
CNN_INPUT_SIZE=112  # Reduced from 224 for faster processing
CNN_INPUT_CHANNELS=3
CNN_NUM_CLASSES=256  # Feature dimension, not actual classes
CNN_BATCH_SIZE=8    # Small batch for memory efficiency
CNN_LEARNING_RATE=0.001
CNN_EPOCHS=3        # Quick training
CNN_WEIGHT_DECAY=1e-5

# LLM Models
LLM_VOCAB_SIZE=8000   # Reduced vocab for faster training
LLM_D_MODEL=256       # Smaller model dimension for speed
LLM_NUM_HEADS=4       # Fewer attention heads
LLM_NUM_LAYERS=3      # Shallow network for 2-hour training
LLM_D_FF=512          # Smaller feed-forward dimension
LLM_MAX_SEQ_LEN=256   # Shorter sequences for efficiency
LLM_BATCH_SIZE=4      # Small batch to fit in memory
LLM_LEARNING_RATE=1e-3  # Higher LR for faster convergence
LLM_EPOCHS=5          # Limited epochs for 2-hour window
LLM_WARMUP_STEPS=100  # Quick warmup

# Vision Transformer (ViT)
VIT_PATCH_SIZE=16
VIT_IMAGE_SIZE=112    # Matched to CNN input
VIT_NUM_CLASSES=256
VIT_D_MODEL=256
VIT_NUM_HEADS=4
VIT_NUM_LAYERS=3
VIT_MLP_DIM=512

# Audio Models
AUDIO_SAMPLE_RATE=16000
AUDIO_N_MELS=80
AUDIO_N_FFT=1024
AUDIO_HOP_LENGTH=256
AUDIO_WIN_LENGTH=1024
AUDIO_MAX_LENGTH=16000

# Multimodal Configuration
# -----------------------
# Enable multimodal capabilities
ENABLE_MULTIMODAL=true

# Vision-Language Model (VLM)
VLM_VISION_ENCODER=mobilenet  # Lightweight vision encoder
VLM_TEXT_ENCODER=distilbert   # Fast text encoder
VLM_FUSION_METHOD=attention    # Cross-modal attention
VLM_HIDDEN_DIM=256            # Compact hidden dimension

# Audio-Visual Model
AV_AUDIO_ENCODER=wav2vec2    # wav2vec2, melspectrogram, mfcc
AV_VISION_ENCODER=resnet18   # resnet18, mobilenet, efficientnet
AV_FUSION_DIM=256

# Cross-Modal Attention
CROSS_MODAL_ATTENTION=true
CROSS_MODAL_HEADS=8
CROSS_MODAL_LAYERS=4

# Training Configuration
# ---------------------
MIXED_PRECISION=true
GRADIENT_CLIPPING=1.0
DROPOUT_RATE=0.1
LABEL_SMOOTHING=0.1

# Data Augmentation
DATA_AUGMENTATION=true
RANDOM_CROP=true
RANDOM_FLIP=true
COLOR_JITTER=true
MIXUP_ALPHA=0.2
CUTMIX_ALPHA=1.0

# Hardware Configuration
# ---------------------
NUM_WORKERS=4
PIN_MEMORY=true
PREFETCH_FACTOR=2

# WARP Scheduler Settings
WARP_COMPUTE_THREADS=auto    # auto, or specific number
WARP_MEMORY_THREADS=4
WARP_CACHE_ALLOCATION=0.8
WARP_ENABLE_PROFILING=true
WARP_ADAPTIVE_SCHEDULING=true

# Memory Management
MEMORY_EFFICIENT=true
GRADIENT_CHECKPOINTING=false
MAX_MEMORY_GB=16

# Logging and Monitoring
# ---------------------
LOG_LEVEL=INFO
LOG_FILE=./logs/cpuwarp_ml.log
TENSORBOARD_DIR=./runs
SAVE_CHECKPOINT_EVERY=1000
MAX_CHECKPOINTS=5

# Evaluation Configuration
# -----------------------
EVAL_EVERY_N_EPOCHS=1
EVAL_BATCH_SIZE=64
SAVE_BEST_MODEL=true
EARLY_STOPPING_PATIENCE=10
METRIC_FOR_BEST_MODEL=accuracy  # accuracy, loss, f1, bleu

# Distributed Training
# ----------------------------
DISTRIBUTED=false
WORLD_SIZE=1
RANK=0
MASTER_ADDR=localhost
MASTER_PORT=12355

# Optimization Flags
# -----------------
COMPILE_MODEL=false  # Model compilation optimization
CHANNELS_LAST=false  # Memory format optimization
FUSED_ADAM=true      # Use fused AdamW optimizer

# Model Architecture Variants
# ---------------------------
# Transformer Variants
TRANSFORMER_VARIANT=standard  # standard, reformer, linformer, performer
ATTENTION_TYPE=full          # full, sparse, local, global

# CNN Variants  
CNN_ARCHITECTURE=resnet      # resnet, densenet, efficientnet, mobilenet
CNN_DEPTH=50                 # 18, 34, 50, 101, 152
CNN_WIDTH_MULTIPLIER=1.0

# Multimodal Architecture
MULTIMODAL_FUSION=late       # early, late, hybrid
MODALITY_DROPOUT=0.1
CROSS_ATTENTION_LAYERS=2

# Fine-tuning Configuration
# ------------------------
PRETRAINED_WEIGHTS=true
FREEZE_BACKBONE=false
FINETUNE_LAST_N_LAYERS=2
LEARNING_RATE_MULTIPLIER=0.1

# Data Pipeline
# ------------
CACHE_DATASET=true
DATASET_CACHE_DIR=./cache
PREPROCESS_NUM_WORKERS=8
SHUFFLE_BUFFER_SIZE=10000

# Model Export
# -----------
EXPORT_ONNX=false
EXPORT_TORCHSCRIPT=false
QUANTIZE_MODEL=false
QUANTIZATION_BITS=8

# Development Settings
# -------------------
DEBUG_MODE=false
PROFILE_MEMORY=false
PROFILE_COMPUTE=false
SAVE_ACTIVATIONS=false
VISUALIZE_GRADIENTS=false